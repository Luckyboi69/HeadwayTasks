{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mpMEcKhrgW2"
   },
   "source": [
    "# Machine Learning: Session 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression, regularization and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ihqFj1pFrgW6"
   },
   "source": [
    "In this task you will experiment with linear regression and see what happens when we use regularized versions of it. More precisely, you will try out Ridge and Lasso regularization. In addition, we will see how using cross-validation helps us to get more stable estimates for our performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3UbfxbEFrgW-"
   },
   "source": [
    "Read in the data in **data.csv** and split it into training (50%) and testing (50%) set. Use random seed 0 (train_test_split method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmuuypBBrgXB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "CRED = '\\033[91m'\n",
    "CEND = '\\033[0m'\n",
    "\n",
    "data = pd.read_csv(\"data.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE STARTS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE ENDS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUMSEYExrgXe"
   },
   "source": [
    "## Task 1. Multivariate linear regression (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9MpPBPoOrgXp"
   },
   "source": [
    "#### <font color='purple'>(a) Implement the fitting procedure of non-regularized multivariate ordinary least squares linear regression, as presented in the lecture slides (matrix operations). Fit on the training data and save the coefficients and the intercept for use in subtask (1c). Print out the coefficients corresponding to the five first features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jb4ZKEeArgXt"
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE STARTS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_five_my_ols_coefficients = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE ENDS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients of five first features according to my OLS implementation:', first_five_my_ols_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-L7ihBRrgX1"
   },
   "source": [
    "#### <font color='purple'>(b) Call out the `sklearn.linear_model.LinearRegression` learning algorithm from the sklearn package. Fit the model on the training data and save it for use in the following subtasks. Print out the coefficients corresponding to the five first features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KAm2_i4PrgX9"
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE STARTS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_five_sklearn_ols_coefficients = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE ENDS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients of five first features according to sklearn OLS implementation:', first_five_sklearn_ols_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qZGgzUlsrgYQ"
   },
   "source": [
    "#### <font color='purple'>(c) Demonstrate that the methods of subtasks (1a) and (1b) give the same results by showing that they find the same coefficients and intercept. </font>\n",
    "\n",
    "You maybe won't get exactly the same results because of precision problems of floats so the idea is to compare if the values are equal up to some precision (e.g. check if the difference is less than 0.000001). If for some reason you are not able to get the assertions to pass with the given precision then please change the precision such that the assertions would pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJ1AqqkUrgYW"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ##### YOUR CODE STARTS ##### (please do not delete this line)\n",
    "    raise NotImplementedError(\"Please assign intercepts and coefficients to the given variables.\")\n",
    "    my_intercept = ...\n",
    "    my_coefficients = ...\n",
    "    sklearn_intercept = ...\n",
    "    sklearn_coefficients = ...\n",
    "    precision = 0.000001\n",
    "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
    "    assert(abs(my_intercept - sklearn_intercept) < precision)\n",
    "    for i in range(99):\n",
    "        assert(abs(my_coefficients[i] - sklearn_coefficients[i]) < precision)\n",
    "    print('The assertions have passed with precision:',precision)\n",
    "except NotImplementedError as e:\n",
    "    print(CRED, \"TODO:\", e, CEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlBDwUAGrgYz"
   },
   "source": [
    "#### <font color='purple'>(d) Using the sklearn model from subtask (1b) predict the results on the training and testing set and calculate and show the root mean square errors (RMSE). Since you need to do the same evaluation in future tasks also, please implement a function 'evaluate' for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XmSVWxLcrgY1"
   },
   "outputs": [],
   "source": [
    "def evaluate(regression_model_class_instance, trainX, trainY, testX, testY):\n",
    "    print(\"\\n#################\\n\")\n",
    "    print(regression_model_class_instance, '\\n')\n",
    "    \n",
    "    ##### YOUR CODE STARTS ##### (please do not delete this line)\n",
    "    raise NotImplementedError(\"Implement RMSE for train and test sets.\")\n",
    "    rmse_tr = ...\n",
    "    rmse_te = ...\n",
    "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
    "    print(\"RMSE train:\", rmse_tr)\n",
    "    print(\"RMSE test:\", rmse_te)\n",
    "    \n",
    "    return rmse_tr, rmse_te\n",
    "\n",
    "try:\n",
    "    ##### YOUR CODE STARTS ##### (please do not delete this line)\n",
    "    evaluate(..., ..., ..., ..., ...)\n",
    "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
    "except NotImplementedError as e:\n",
    "    print(CRED, \"TODO:\", e, CEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZB8XMDbrgZ5"
   },
   "source": [
    "## Task 2. Ridge & Lambda regularized regression  (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0JPqAyeqrgZ7"
   },
   "source": [
    "This blogpost might clarify regularization a bit: https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c\n",
    "\n",
    "Intuition behind the regularization: https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8DGnURMUrgaK"
   },
   "source": [
    "#### <font color='purple'>(a) Implement the fitting procedure of ridge regression, as presented in the lecture slides (matrix operations). Fit on the training data with regularization parameter equal to 1 and save the coefficients and the intercept for use in subtask (2c). Print out the coefficients corresponding to the five first features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE STARTS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_five_my_ridge_coefficients = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VL0VxlXRrgal"
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE ENDS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients of five first features according to my ridge implementation:', first_five_my_ridge_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uNO6u0zxrgbp"
   },
   "source": [
    "#### <font color='purple'>(b) Call out the `sklearn.linear_model.Ridge` learning algorithm from the sklearn package. Fit the model on the training data with regularization parameter equal to 1 and save it for use in the following subtasks. Print out the coefficients corresponding to the five first features.</font>\n",
    "\n",
    "Use parameters `solver = \"cholesky\", tol = 0.000000000001` in order to get more similar results to your own implementation. The default parameter for the regularization is already 1 so no need to specify that. The parameters `solver` and `tol` are necessary to force sklearn to use closed-form solution. Otherwise it would use numerical optimization which would give more different results from yours. **In the future tasks, please use the default option and don't force it to use the closed-form solution (numerical will be faster!).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HIgmQ8efrgb2"
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE STARTS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_five_sklearn_ridge_coefficients = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE ENDS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients of five first features according to my ridge implementation:', first_five_sklearn_ridge_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-y4Lqo9rgcs"
   },
   "source": [
    "#### <font color='purple'>(c) Demonstrate the correctess of your implementation the same way as in the previous exercise. For this compare your coefficients and intercept as obtained in subtask (2a) with the coeffiecients and intercept from sklearn, as obtained in subtask (2b). The results can actually vary quite a bit due to implementation differences in matrix operations. Compare that the differences in results (coefficients and intercept) are less than 0.02. If for some reason you are not able to get the assertions to pass with the given precision then please change the precision such that the assertions would pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxuOfk9Yrgcv"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ##### YOUR CODE STARTS ##### (please do not delete this line)\n",
    "    raise NotImplementedError(\"Please assign intercepts and coefficients to the given variables.\")\n",
    "    my_ridge_intercept = ...\n",
    "    my_ridge_coefficients = ...\n",
    "    sklearn_ridge_intercept = ...\n",
    "    sklearn_ridge_coefficients = ...\n",
    "    precision = 0.02\n",
    "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
    "    assert(abs(my_ridge_intercept - sklearn_ridge_intercept) < precision)\n",
    "    for i in range(99):\n",
    "        assert(abs(my_ridge_coefficients[i] - sklearn_ridge_coefficients[i]) < precision)\n",
    "    print('The assertions have passed with precision:',precision)\n",
    "except NotImplementedError as e:\n",
    "    print(CRED, \"TODO:\", e, CEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khdbJkRirgdQ"
   },
   "source": [
    "#### <font color='purple'>(d) Train a Lasso model using the sklearn package (use the default regularization parameter) and save it for future use. Print out the coefficients corresponding to the five first features.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "F6W0Syy6rgdS"
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE STARTS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_five_sklearn_lasso_coefficients = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE ENDS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients of five first features according to sklearn lasso implementation:', first_five_sklearn_lasso_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EIbGggTrgd3"
   },
   "source": [
    "#### <font color='purple'>(e) Evaluate the sklearn Ridge and Lasso models on the training and testing set and calculate and show the RMSE, using the function 'evaluate' from subtask (1d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhC5F0Bkrgd5"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print('Evaluation of sklearn ridge regression model:')\n",
    "    ##### YOUR CODE STARTS ##### (please do not delete this line)\n",
    "    evaluate(..., ..., ..., ..., ...)\n",
    "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
    "    \n",
    "    print('Evaluation of sklearn lasso regression model:')\n",
    "    ##### YOUR CODE STARTS ##### (please do not delete this line)\n",
    "    evaluate(..., ..., ..., ..., ...)\n",
    "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
    "except NotImplementedError as e:\n",
    "    print(CRED, \"TODO:\", e, CEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x7LHNfh3rgeB"
   },
   "source": [
    "## Task 3. Choosing a suitable regularization parameter  (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBMOuzErrgeO"
   },
   "source": [
    "Since different parameters can lead to very different results we need to do some parameter tuning and find a suitable regularization parameter for both Ridge and Lasso. We could try out different values and see which ones lead to the best results on the test set. However, then we would overfit to our test data and we would not have an adequate estimate of how good the model is in the end. That is why we need to do parameter tuning only using the training set.\n",
    "\n",
    "Use **alphas = np.linspace(0.01, 10, 100)** for Ridge and **alphas = np.linspace(0.01, 5, 100)** for Lasso. The method generates 100 values with equal steps between the first and second parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4zxI4YkTrgef"
   },
   "source": [
    "#### <font color='purple'>(a) **Method 1:** Divide the training set into training and validation set using 90%/10% split and a random seed 0 (train_test_split method). Train Ridge and Lasso models with different alpha values on the training set and calculate the RMSE values on the validation set. Choose and report the alpha that has the best RMSE for Ridge and another alpha that has the best RMSE for Lasso (save both alpha and RMSE values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aP3DO7GArgey"
   },
   "outputs": [],
   "source": [
    "def method_1(model,alphas,random_seed):\n",
    "    ##### YOUR CODE STARTS ##### (please do not delete this line)\n",
    "    raise NotImplementedError(\"Calculate RMSE for Ridge and Lasso models.\")\n",
    "    ...\n",
    "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
    "    return best_alpha,rmse\n",
    "\n",
    "try:\n",
    "    ##### YOUR CODE STARTS ##### (please do not delete this line)\n",
    "    method_1(..., ..., ...) ## ridge\n",
    "    method_1(..., ..., ...) ## lasso\n",
    "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
    "except NotImplementedError as e:\n",
    "    print(CRED, \"TODO:\", e, CEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8O3tUFzBrgfE"
   },
   "source": [
    "#### <font color='purple'>(b) **Method 2:** Instead of doing only one training/validation split, use 10-fold cross validation. For each alpha value calculate the validation errors for each of the folds and average the results. Then choose and report the alpha that has the best RMSE for Ridge and another alpha that has best RMSE for Lasso (save both alpha and RMSE values). For doing the 10-fold split use the sklearn method KFold (kf = KFold(n_splits=10, random_state = 0, shuffle = True)). To see more about how to iterate through the folds see the documentation for the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEDmkZNdrgfN"
   },
   "outputs": [],
   "source": [
    "def method_2(model,alphas,random_seed):\n",
    "    ##### YOUR CODE STARTS ##### (please do not delete this line)\n",
    "    raise NotImplementedError(\"Implement 10-fold cross-validation.\") \n",
    "    ...\n",
    "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
    "    return best_alpha,rmse\n",
    "try:\n",
    "    ##### YOUR CODE STARTS ##### (please do not delete this line)\n",
    "    method_2(..., ..., ...) ## ridge\n",
    "    method_2(..., ..., ...) ## lasso\n",
    "    ##### YOUR CODE ENDS ##### (please do not delete this line)\n",
    "except NotImplementedError as e:\n",
    "    print(CRED, \"TODO:\", e, CEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXdDbPANrgfo"
   },
   "source": [
    "## Task 4. Comparing the stability of Method 1 and Method 2  (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78YSJCQprggD"
   },
   "source": [
    "#### <font color='purple'>(a) Run Method 1 and Method 2 both 10 times, every time using a different value 0,1,2,...,9 as the random_state. Report the best alpha and RMSE for both parameter tuning methods and for both regularization methods for each of the 10 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ludiQ_eVrggc"
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE STARTS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE ENDS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LloCKK0srggh"
   },
   "source": [
    "#### <font color='purple'>(b) What can you say about the stability of the methods? Which one gives more stable information about which alpha to use? Which alpha values turn out to be best in the end for these data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NLHTnRkrggi"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BX9NcjAargg5"
   },
   "source": [
    "#### <font color='purple'>(c) Create two plots (one for Ridge and one for Lasso) where on each plot there are two boxplots - one for showing the distribution of the RMSE values for the 10 trials for Method 1 and the other for Method 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4ZAWjj4irgg7"
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE STARTS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE ENDS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5J5EGGirghH"
   },
   "source": [
    "#### <font color='purple'>(d) Comment on why the results look like they do? In general, when tuning parameters, is it better to use one training-validation split or K-fold cross-validation? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2aciNQMrghJ"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjGQ8zLErghK"
   },
   "source": [
    "## Task 5. Regularization parameter effect on the coefficients  (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M241kW8MrghM"
   },
   "source": [
    "#### <font color='purple'>(a) The regularization parameter influences the values of the coefficients. Create two plots (one for Ridge and one for Lasso) that have the regularization parameter on the x-axis and coefficient values on the y-axis. You don't have to take all 99 values, you can take for example the first 20. Show each coefficient as a line (on the same plot) and comment on what happens when the regularization parameter increases. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE STARTS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XNFnFd6GrghT"
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE ENDS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ET4Npwibrghn"
   },
   "source": [
    "#### <font color='purple'>(b) What does Ridge regression do and what does Lasso regression do? How do they differ? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_5BAu77rghp"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sWuThxLJrghq"
   },
   "source": [
    "## Task 6. Evaluating different models  (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2b91miZrghr"
   },
   "source": [
    "#### <font color='purple'>(a) Choose the values of alpha for Ridge and Lasso according to subtask (4b). Now let's see which model works best for our data by evaluating the test RMSE. Compare the following models by reporting the training and testing set RMSE: </font>\n",
    "\n",
    "1. Non-regularized linear regression\n",
    "2. Ridge regression with your chosen parameter\n",
    "3. Lasso regression with your chosen parameter\n",
    "4. A \"dumb\" model that always predicts the mean value of y_train\n",
    "5. An ideal model that the instructors have used for generating the data (the true coefficients are [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 0, ..., 0] and intercept 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qUmwuUBjrght"
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE STARTS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### YOUR CODE ENDS ##### (please do not delete this line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qgoYXKLNrgh4"
   },
   "source": [
    "#### <font color='purple'>(b) Which method gives the best results and by looking at which value do you claim that? Why did this method work the best in your opinion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5rguRr0rgh6"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EflwOObYrgiB"
   },
   "source": [
    "#### <font color='purple'>(c) Were all of the \"smart\" models better than the \"dumb\" one (baseline). What would it mean if the learned model would give worse results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmoDn4DOrgiJ"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ay6Gws1OrgiL"
   },
   "source": [
    "#### <font color='purple'>(d) Were the learned models far from the ideal one? Were the learned coefficients similar to the true ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lNGwKZ1jrgiN"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edUWkelmrgiO"
   },
   "source": [
    "#### <font color='purple'>(e) Which model overfitted the most, how can you see that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvcBOUuQrgiQ"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQvCr7vqrgiY"
   },
   "source": [
    "#### <font color='purple'>(f) Are regularized methods always better than methods without regularization (not only in this case but in general). Why/why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZCgKEIGzrgic"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <font color='red'>This was the last task! Please restart and run all before submission!</font>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "HW2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
